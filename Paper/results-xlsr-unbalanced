Step	Training Loss	Validation Loss	Accuracy	F1 Score	Mse	Mae	Mae^m
100	    1.666300	1.702984	0.340599	0.072590	2.926431	1.204360	2.285714
200	    1.711500	1.697713	0.234332	0.054242	2.008174	1.130790	1.857143
300	    1.748400	1.666050	0.340599	0.072590	2.926431	1.204360	2.285714
400	    1.545200	1.730879	0.340599	0.072590	2.926431	1.204360	2.285714
500	    1.687700	1.681787	0.340599	0.072738	2.912807	1.201635	2.282675
600	    1.775500	1.681883	0.354223	0.120505	2.416894	1.103542	2.021948
700	    1.633400	1.648669	0.340599	0.072590	2.926431	1.204360	2.285714
800	    1.739500	1.673530	0.340599	0.072590	2.926431	1.204360	2.285714
900	    1.632600	1.716966	0.340599	0.072590	2.926431	1.204360	2.285714
1000	1.724700	1.673659	0.340599	0.072590	2.926431	1.204360	2.285714
1100	1.747800	1.675785	0.348774	0.116049	2.487738	1.119891	2.051952
1200	1.697400	1.679045	0.340599	0.072590	2.926431	1.204360	2.285714
1300	1.647100	1.671008	0.348774	0.117228	2.444142	1.108992	2.038487
1400	1.668400	1.671081	0.356948	0.109960	2.599455	1.133515	2.110697
1500	1.736900	1.669626	0.340599	0.072590	2.926431	1.204360	2.285714
1600	1.639200	1.663493	0.340599	0.072590	2.926431	1.204360	2.285714
1700	1.625900	1.667512	0.340599	0.072590	2.926431	1.204360	2.285714
1800	1.694300	1.665160	0.340599	0.072590	2.926431	1.204360	2.285714
1900	1.660500	1.669466	0.340599	0.072590	2.926431	1.204360	2.285714
2000	1.582100	1.679060	0.340599	0.072590	2.926431	1.204360	2.285714
2100	1.767800	1.660924	0.340599	0.072590	2.926431	1.204360	2.285714
2200	1.720700	1.667948	0.340599	0.072590	2.926431	1.204360	2.285714
2300	1.644000	1.646667	0.340599	0.072738	2.912807	1.201635	2.282675
2400	1.637900	1.650486	0.340599	0.072738	2.912807	1.201635	2.282675
2500	1.542500	1.633940	0.356948	0.097525	2.585831	1.130790	2.085996
2600	1.786500	1.644748	0.356948	0.120208	2.490463	1.106267	2.027609
2700	1.610400	1.618731	0.362398	0.119617	2.498638	1.108992	2.045084
2800	1.621100	1.624351	0.343324	0.084479	2.765668	1.174387	2.180134
2900	1.603900	1.607627	0.348774	0.111918	2.397820	1.100817	2.013273
3000	1.645700	1.605005	0.359673	0.153412	2.212534	1.068120	1.724660
3100	1.546800	1.593343	0.381471	0.129622	2.416894	1.081744	1.884915
3200	1.639000	1.595497	0.324251	0.137428	2.234332	1.106267	1.597969
3300	1.574000	1.642315	0.321526	0.142399	2.133515	1.087193	1.614342
3400	1.471500	1.577438	0.356948	0.149073	2.152589	1.046322	1.693757
3500	1.494400	1.663610	0.337875	0.139254	2.106267	1.054496	1.702916
3600	1.510900	1.609881	0.329700	0.150058	2.106267	1.065395	1.597222
3700	1.468800	1.676976	0.316076	0.147351	2.013624	1.059946	1.515525
3800	1.336200	1.761189	0.310627	0.141314	2.106267	1.087193	1.657779

Evaluate:
labels: [2 3 3 4 3 3 1 2 4 3 5 3 1 5 0 6 1 4 2 4 3 0 5 2 0 4 7 1 3 6 5 0 6 3 3 0 2
 1 2 3 5 1 3 0 2 4 5 1 6 6 5 1 0 4 3 5 5 0 3 0 1 6 6 0 6 5 4 1 2 0 6 4 6 0
 1 6 4 3 5 3 3 4 5 4 6 6 1 5 5 0 0 2 4 6 6 5 6 5 2 2 0 1 5 1 4 5 0 3 0 1 2
 2 3 0 5 3 2 1 0 1 5 2 1 6 4 6 4 0 4 5 2 1 3 6 0 0 2 4 5 3 2 2 6 0 5 4 0 0
 5 6 4 0 0 5 5 5 4 2 0 6 2 1 0 3 5 1 0 2 5 3 1 1 5 4 5 1 0 1 0 5 2 3 2 5 0
 5 3 6 1 6 2 3 5 3 4 3 4 3 6 5 2 4 2 5 0 1 4 0 0 0 2 2 5 2 2 1 2 2 6 3 3 6
 1 5 0 5 6 4 1 6 3 2 6 1 6 0 1 0 0 4 3 0 0 1 6 2 1 6 7 3 0 6 2 4 6 3 5 2 2
 5 6 5 2 5 0 3 2 5 5 1 4 6 4 1 0 5 4 4 4 0 5 3 5 0 3 1 6 1 0 3 1 1 4 5 4 2
 6 0 4 3 2 6 0 3 3 4 1 3 1 2 0 4 4 6 6 3 1 3 6 5 4 5 5 1 4 1 6 1 4 4 3 0 6
 2 2 1 0 4 5 2 1 2 1 2]
preds: [1 1 3 3 1 2 1 3 1 2 2 4 1 1 1 3 1 1 2 1 1 2 1 1 1 2 4 1 3 1 2 1 4 1 1 2 3
 1 2 2 2 2 3 2 2 4 3 1 2 1 4 1 1 2 1 3 3 1 1 1 1 2 2 1 3 3 1 2 2 1 1 2 1 1
 4 1 2 1 3 3 3 1 2 3 1 3 1 2 3 1 1 2 1 2 3 3 1 2 1 1 2 2 1 1 3 3 1 3 1 1 2
 2 4 2 1 3 1 1 1 1 3 1 3 1 1 2 1 1 2 1 3 1 3 1 2 1 3 1 2 3 2 3 3 2 1 1 1 1
 3 3 4 1 2 2 1 1 1 1 1 3 1 1 1 1 2 1 1 3 2 3 3 2 1 3 3 3 3 1 2 2 3 2 2 4 1
 2 4 4 1 3 3 2 3 3 3 4 1 3 3 2 3 3 1 3 1 1 3 1 1 1 1 1 3 1 1 1 3 1 1 3 1 4
 1 4 1 2 2 3 1 1 3 1 1 1 3 1 1 1 2 1 1 1 2 3 2 1 2 2 2 2 1 1 1 1 2 3 3 1 4
 3 1 1 1 2 1 1 2 4 3 1 2 3 3 1 1 3 4 3 1 1 1 1 4 1 2 1 2 1 1 1 1 1 3 2 1 1
 1 1 3 4 1 2 1 1 1 1 1 3 2 2 1 3 1 3 1 3 1 3 2 4 3 2 3 1 4 3 3 1 1 2 1 1 3
 1 1 1 1 1 3 1 1 1 2 3]
              precision    recall  f1-score   support

       teens       0.00      0.00      0.00        54
    twenties       0.22      0.73      0.33        49
    thirties       0.15      0.23      0.18        48
    fourties       0.22      0.38      0.28        47
     fifties       0.19      0.09      0.12        45
     sixties       0.00      0.00      0.00        54
   seventies       0.00      0.00      0.00        45
    eighties       0.00      0.00      0.00         2

    accuracy                           0.20       344
   macro avg       0.10      0.18      0.11       344
weighted avg       0.11      0.20      0.13       344

[[ 0 42 11  1  0  0  0  0]
 [ 0 36  7  5  1  0  0  0]
 [ 0 25 11 11  1  0  0  0]
 [ 0 17  7 18  5  0  0  0]
 [ 0 20  7 14  4  0  0  0]
 [ 0 11 17 20  6  0  0  0]
 [ 0 16 12 14  3  0  0  0]
 [ 0  0  1  0  1  0  0  0]]

{'eval_loss': 2.4132931232452393,
 'eval_model_preparation_time': 0.0062,
 'eval_accuracy': 0.2005813953488372,
 'eval_f1_score': 0.11416083916083915,
 'eval_MSE': 4.8023255813953485,
 'eval_MAE': 1.697674418604651,
 'eval_MAE^M': 1.9871339818433285,
 'eval_runtime': 27.4629,
 'eval_samples_per_second': 12.526,
 'eval_steps_per_second': 1.566}