Step	T Loss	    V Loss	    Accuracy	F1 Score	Mse	Mae	Mae^m
100	1.707100	1.659937	0.311953	0.222532	3.285714	1.285714	1.227939
200	1.280000	1.217010	0.510204	0.399649	1.303207	0.720117	0.743291
300	1.224100	1.126608	0.518950	0.438310	1.370262	0.717201	0.873884
400	1.007100	1.111552	0.574344	0.501878	1.137026	0.600583	0.763671
500	0.865800	1.115767	0.641399	0.540712	1.454810	0.603499	0.666461
600	0.665300	0.954688	0.676385	0.602117	0.886297	0.472303	0.531457
700	0.710600	1.046575	0.670554	0.590829	0.903790	0.483965	0.669525
800	0.532600	1.251972	0.655977	0.696066	0.781341	0.472303	0.406733
900	0.425800	1.143105	0.693878	0.607972	0.860058	0.451895	0.513383
1000	0.452000	1.024279	0.711370	0.706641	0.892128	0.443149	0.381787
1100	0.239900	1.285634	0.711370	0.709491	0.790087	0.422741	0.368317
1200	0.156400	1.501369	0.667638	0.705039	1.192420	0.539359	0.464035
1300	0.396200	1.333811	0.723032	0.754502	0.755102	0.411079	0.359940
1400	0.147500	1.725638	0.688047	0.723012	0.868805	0.466472	0.410243
1500	0.275700	1.645553	0.708455	0.705310	0.650146	0.399417	0.346924
1600	0.124500	1.903380	0.705539	0.746433	0.897959	0.448980	0.386902
1700	0.090200	1.894289	0.728863	0.719530	0.816327	0.413994	0.362615
1800	0.118800	2.052877	0.737609	0.765750	0.717201	0.384840	0.340513
1900	0.057300	2.055331	0.717201	0.751199	0.848397	0.428571	0.366608
2000	0.112300	2.191491	0.717201	0.753803	0.740525	0.408163	0.354784
2100	0.146300	2.091400	0.725948	0.759955	0.658892	0.379009	0.327192
2200	0.364100	2.550109	0.699708	0.738786	0.892128	0.448980	0.383938
2300	0.049500	2.590050	0.702624	0.698553	0.903790	0.460641	0.398940
2400	0.017700	2.233619	0.720117	0.756432	0.892128	0.437318	0.375652
2500	0.029100	2.694864	0.734694	0.769245	0.740525	0.390671	0.339099
2600	0.079900	2.549660	0.720117	0.747913	0.717201	0.402332	0.349600
2700	0.098200	2.408723	0.746356	0.777060	0.682216	0.373178	0.320340
2800	0.072000	2.269856	0.728863	0.765796	0.717201	0.396501	0.340151
2900	0.122700	2.390592	0.740525	0.775839	0.670554	0.373178	0.318806
3000	0.007500	2.332188	0.737609	0.771690	0.647230	0.373178	0.321045
3100	0.001900	2.451357	0.743440	0.777923	0.641399	0.367347	0.313275
3200	0.029500	2.443158	0.749271	0.781306	0.673469	0.370262	0.316969
3300	0.001200	2.485085	0.752187	0.785916	0.583090	0.344023	0.295473
3400	0.020000	2.903002	0.725948	0.760904	0.734694	0.396501	0.340334
3500	0.034100	2.686170	0.734694	0.768952	0.746356	0.396501	0.341208
3600	0.013600	2.628152	0.734694	0.768549	0.731778	0.393586	0.341525
3700	0.025200	2.726761	0.737609	0.772938	0.629738	0.367347	0.312924
3800	0.040300	2.549428	0.743440	0.775314	0.667638	0.370262	0.321296
3900	0.001300	2.488187	0.758017	0.788992	0.673469	0.358601	0.308300
4000	0.011300	2.521255	0.763848	0.793663	0.562682	0.329446	0.278057
4100	0.037100	2.601691	0.763848	0.796248	0.539359	0.329446	0.278475
4200	0.001400	2.514499	0.775510	0.804444	0.501458	0.309038	0.261624
4300	0.010700	2.474181	0.772595	0.801665	0.513120	0.314869	0.271710
4400	0.000200	2.481095	0.760933	0.791534	0.533528	0.329446	0.283015
4500	0.000100	2.491146	0.760933	0.792089	0.548105	0.332362	0.284222


 [43/43 00:21]
labels: [4 6 6 0 3 1 3 2 4 6 6 2 5 0 0 1 0 4 3 4 5 2 4 5 5 1 5 5 0 3 5 1 2 5 5 0 5
 0 5 1 6 0 1 1 2 4 2 0 0 3 0 4 0 1 1 0 2 3 6 6 2 1 2 4 6 0 5 4 3 3 6 0 0 0
 5 0 5 5 4 5 0 3 4 2 5 1 6 4 2 3 5 4 5 2 1 3 2 2 6 4 3 3 0 3 0 4 0 4 5 5 1
 0 6 5 0 2 4 5 5 5 6 1 5 4 1 2 4 4 5 6 4 4 6 5 0 6 3 3 2 5 4 3 4 3 4 0 7 6
 3 6 1 1 1 0 0 0 4 2 2 1 3 6 4 6 5 0 3 5 1 0 2 0 0 2 4 4 2 3 0 2 4 2 2 4 4
 4 0 3 4 3 4 5 5 5 2 4 2 2 0 0 5 0 6 4 4 1 2 4 3 6 3 2 2 6 0 2 2 1 5 2 1 1
 0 0 5 0 6 1 2 4 6 6 5 6 2 0 2 6 3 1 1 0 6 0 3 6 2 5 5 6 6 1 5 3 0 3 7 2 1
 0 0 0 6 6 0 2 4 5 5 3 1 5 6 3 4 5 4 0 4 0 4 2 0 2 4 3 3 4 5 1 4 5 5 5 4 4
 3 6 1 0 1 0 4 0 1 4 2 3 2 0 4 3 0 0 4 4 1 4 6 3 3 5 6 2 6 4 5 1 5 2 5 0 5
 3 1 2 0 6 6 6 6 5 6 5]
preds: [4 6 6 1 1 1 3 2 4 6 6 2 5 0 1 1 1 4 3 3 5 2 5 0 5 0 5 5 0 2 5 0 2 5 5 0 5
 0 5 1 6 0 1 1 0 4 2 0 1 3 0 4 0 1 4 1 2 3 6 6 2 0 3 3 6 2 5 5 1 3 6 0 1 2
 2 1 5 5 4 6 0 6 2 0 5 0 6 4 3 3 5 4 3 1 1 2 2 2 6 4 3 5 0 0 2 4 0 4 5 2 1
 0 6 5 0 2 4 5 5 5 6 1 5 4 2 1 4 4 5 6 4 5 6 5 0 6 4 3 2 6 4 3 4 2 4 2 7 6
 4 6 1 1 0 0 0 1 4 2 2 1 3 6 4 6 5 0 3 5 1 0 2 0 0 2 3 5 1 3 1 2 2 2 2 4 4
 4 1 0 1 3 4 5 3 6 2 4 1 2 0 0 5 0 6 4 4 1 2 4 3 6 2 0 5 6 0 2 2 1 5 2 1 1
 1 0 5 0 3 1 2 4 6 6 5 6 5 0 2 6 3 1 2 1 6 0 3 6 1 5 5 6 6 1 5 3 0 3 7 1 1
 0 0 0 6 6 0 2 4 5 5 3 1 5 6 3 4 5 4 0 4 0 4 2 0 2 1 3 3 2 5 1 4 5 5 5 4 4
 3 3 2 1 0 2 4 0 2 4 2 3 2 1 4 3 0 0 4 4 1 3 6 3 3 5 6 3 6 4 5 0 5 1 5 1 5
 3 1 2 1 6 6 6 6 3 6 4]
              precision    recall  f1-score   support

       teens       0.75      0.66      0.70        61
    twenties       0.48      0.68      0.56        37
    thirties       0.64      0.68      0.66        47
    fourties       0.70      0.70      0.70        40
     fifties       0.92      0.77      0.84        57
     sixties       0.87      0.82      0.84        56
   seventies       0.91      0.95      0.93        44
    eighties       1.00      1.00      1.00         2

    accuracy                           0.75       344
   macro avg       0.78      0.78      0.78       344
weighted avg       0.77      0.75      0.76       344

[[40 16  5  0  0  0  0  0]
 [ 7 25  4  0  1  0  0  0]
 [ 3  7 32  3  0  2  0  0]
 [ 2  2  4 28  2  1  1  0]
 [ 0  2  3  4 44  4  0  0]
 [ 1  0  2  3  1 46  3  0]
 [ 0  0  0  2  0  0 42  0]
 [ 0  0  0  0  0  0  0  2]]

 [43/43 00:20]
labels: [2 3 3 4 3 3 1 2 4 3 5 3 1 5 0 6 1 4 2 4 3 0 5 2 0 4 7 1 3 6 5 0 6 3 3 0 2
 1 2 3 5 1 3 0 2 4 5 1 6 6 5 1 0 4 3 5 5 0 3 0 1 6 6 0 6 5 4 1 2 0 6 4 6 0
 1 6 4 3 5 3 3 4 5 4 6 6 1 5 5 0 0 2 4 6 6 5 6 5 2 2 0 1 5 1 4 5 0 3 0 1 2
 2 3 0 5 3 2 1 0 1 5 2 1 6 4 6 4 0 4 5 2 1 3 6 0 0 2 4 5 3 2 2 6 0 5 4 0 0
 5 6 4 0 0 5 5 5 4 2 0 6 2 1 0 3 5 1 0 2 5 3 1 1 5 4 5 1 0 1 0 5 2 3 2 5 0
 5 3 6 1 6 2 3 5 3 4 3 4 3 6 5 2 4 2 5 0 1 4 0 0 0 2 2 5 2 2 1 2 2 6 3 3 6
 1 5 0 5 6 4 1 6 3 2 6 1 6 0 1 0 0 4 3 0 0 1 6 2 1 6 7 3 0 6 2 4 6 3 5 2 2
 5 6 5 2 5 0 3 2 5 5 1 4 6 4 1 0 5 4 4 4 0 5 3 5 0 3 1 6 1 0 3 1 1 4 5 4 2
 6 0 4 3 2 6 0 3 3 4 1 3 1 2 0 4 4 6 6 3 1 3 6 5 4 5 5 1 4 1 6 1 4 4 3 0 6
 2 2 1 0 4 5 2 1 2 1 2]
preds: [2 3 3 4 2 3 1 2 4 3 5 3 1 5 0 6 1 4 2 4 3 2 5 2 0 4 7 1 3 6 5 0 6 3 3 0 5
 1 2 3 5 1 3 0 2 4 3 1 6 6 5 1 0 4 0 5 5 0 3 0 1 6 6 0 6 5 4 1 2 0 6 4 6 0
 1 6 4 0 5 3 3 4 5 4 6 6 1 5 5 0 0 2 4 6 6 5 6 5 2 2 0 2 5 1 4 3 0 3 0 1 2
 2 3 1 5 3 2 1 2 0 5 2 1 6 4 6 4 0 4 5 4 1 3 6 0 0 2 4 5 3 2 2 6 0 5 4 0 0
 5 6 4 0 0 5 5 5 4 2 0 6 1 1 0 3 5 1 0 2 5 3 1 1 5 4 5 1 1 1 0 5 2 3 2 5 0
 5 3 6 0 6 2 3 5 3 4 3 4 3 6 5 2 4 2 5 0 1 4 0 0 0 2 2 5 2 2 1 2 2 6 3 1 6
 1 5 0 5 6 4 1 6 3 2 6 1 6 0 1 0 0 4 3 0 0 1 6 2 1 6 7 3 0 6 2 4 6 3 5 2 2
 5 6 5 2 5 1 3 2 5 5 1 2 6 4 1 0 5 4 5 4 0 5 3 5 0 3 1 6 1 0 3 1 1 3 5 4 2
 6 0 4 3 2 6 0 3 3 4 1 3 1 2 0 4 5 6 6 3 1 3 6 5 4 5 5 1 4 1 6 1 4 4 3 0 6
 2 2 1 0 4 5 2 1 2 1 2]
              precision    recall  f1-score   support

       teens       0.92      0.91      0.92        54
    twenties       0.90      0.94      0.92        49
    thirties       0.90      0.94      0.92        48
    fourties       0.93      0.91      0.92        47
     fifties       0.98      0.91      0.94        45
     sixties       0.95      0.96      0.95        54
   seventies       1.00      1.00      1.00        45
    eighties       1.00      1.00      1.00         2

    accuracy                           0.94       344
   macro avg       0.95      0.95      0.95       344
weighted avg       0.94      0.94      0.94       344

[[49  3  2  0  0  0  0  0]
 [ 2 46  1  0  0  0  0  0]
 [ 0  1 45  0  1  1  0  0]
 [ 2  1  1 43  0  0  0  0]
 [ 0  0  1  1 41  2  0  0]
 [ 0  0  0  2  0 52  0  0]
 [ 0  0  0  0  0  0 45  0]
 [ 0  0  0  0  0  0  0  2]]
{'eval_loss': 0.654279351234436,
 'eval_model_preparation_time': 0.0024,
 'eval_accuracy': 0.938953488372093,
 'eval_f1_score': 0.9469554445251152,
 'eval_MSE': 0.19186046511627908,
 'eval_MAE': 0.09883720930232558,
 'eval_MAE^M': 0.0865660832891076,
 'eval_runtime': 21.5519,
 'eval_samples_per_second': 15.961,
 'eval_steps_per_second': 1.995}