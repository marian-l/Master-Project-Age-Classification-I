Step	Training Loss	Validation Loss	Accuracy	F1 Score	Mse	Mae	Mae^m
100	    1.968900	    1.961521	0.169096	0.036160	3.737609	1.609329	2.000000
200	    1.810600	    1.638887	0.393586	0.266914	3.618076	1.285714	1.370188
300	    1.708400	    1.639791	0.294461	0.175511	2.565598	1.131195	1.191857
400	    1.352800	    1.700683	0.370262	0.275140	5.224490	1.539359	2.145225
500	    1.473300	    1.649054	0.300292	0.281039	2.845481	1.189504	1.489731
600	    1.412200	    1.281453	0.510204	0.390216	2.731778	0.994169	1.028783
700	    1.054100	    1.238467	0.489796	0.421441	1.664723	0.790087	0.774463
800	    1.065900	    1.066616	0.533528	0.450340	1.195335	0.658892	0.669649
900	    0.880000	    1.295183	0.591837	0.496494	1.798834	0.737609	0.897504
1000	1.064800	    1.189350	0.568513	0.471219	2.110787	0.839650	0.861957
1100	0.822900	    0.960695	0.664723	0.570759	1.227405	0.562682	0.602456
1200	0.699600	    0.991310	0.623907	0.533342	1.583090	0.661808	0.739833
1300	0.677400	    0.945514	0.661808	0.681558	0.874636	0.489796	0.470820
1400	0.509100	    0.996231	0.641399	0.623684	0.927114	0.513120	0.504737
1500	0.479700	    0.981552	0.682216	0.637175	1.195335	0.513120	0.533285




 [4243/6870 3:23:45 < 2:06:12, 0.35 it/s, Epoch 18.52/30]
Step	Training Loss	Validation Loss	Accuracy	F1 Score	Mse	Mae	Mae^m
100	1.963000	1.992247	0.151603	0.049290	4.011662	1.702624	1.978880
200	1.933400	1.916466	0.183673	0.070531	5.002915	1.842566	2.061994
300	1.677200	1.988441	0.250729	0.145105	9.781341	2.376093	2.567490
400	1.719700	1.592253	0.425656	0.301475	3.857143	1.274052	1.264946
500	1.660300	1.710918	0.344023	0.241294	5.565598	1.664723	1.816279
600	1.537300	1.540129	0.370262	0.269080	3.784257	1.300292	1.520258
700	1.408100	1.629318	0.413994	0.313019	2.871720	1.122449	1.172620
800	1.313200	1.576212	0.387755	0.302008	3.985423	1.338192	1.664701
900	1.422700	1.569554	0.434402	0.314750	3.918367	1.288630	1.409038
1000	1.282300	1.276847	0.492711	0.412373	1.988338	0.857143	0.881337
1100	1.288000	1.350340	0.533528	0.431120	2.618076	0.938776	1.140304
1200	1.230400	1.429439	0.501458	0.431052	2.271137	0.895044	1.138442
1300	0.957200	1.380004	0.466472	0.382767	2.215743	0.915452	1.044203
1400	1.027300	1.283839	0.504373	0.408442	2.090379	0.860058	1.132094
1500	1.078500	1.401882	0.521866	0.435954	2.215743	0.874636	1.028719
1600	0.930100	1.328744	0.536443	0.444100	1.991254	0.842566	1.105882
1700	1.110100	1.340153	0.574344	0.468131	2.227405	0.827988	0.926069
1800	1.006400	1.264804	0.571429	0.507233	1.481050	0.693878	0.973984
1900	0.817800	1.325922	0.618076	0.538130	1.693878	0.679300	0.843267
2000	0.910100	1.264514	0.553936	0.466841	1.615160	0.752187	0.911475
2100	0.662200	1.311988	0.606414	0.594817	1.857143	0.725948	0.712813
2200	0.617800	1.564509	0.539359	0.436220	1.772595	0.763848	0.862133
2300	0.679200	1.389895	0.568513	0.506050	1.883382	0.752187	0.796851
2400	0.713700	1.256952	0.594752	0.520144	1.857143	0.743440	1.082801
2500	0.565100	1.454999	0.594752	0.588530	1.553936	0.690962	0.795829
2600	0.412800	1.475436	0.591837	0.577780	1.696793	0.717201	0.753879
2700	0.691400	1.830365	0.588921	0.506594	1.679300	0.723032	0.825008
2800	0.440300	1.771608	0.612245	0.532546	1.725948	0.699708	0.807188
2900	0.556400	1.866173	0.580175	0.532847	1.568513	0.693878	0.744774
3000	0.459600	1.676680	0.618076	0.594231	1.644315	0.682216	0.737176
3100	0.337600	2.143403	0.565598	0.496885	2.087464	0.827988	1.214538
3200	0.338500	1.809653	0.586006	0.509707	1.708455	0.723032	0.827683
3300	0.413000	1.919116	0.586006	0.544673	1.612245	0.720117	0.775742
3400	0.374500	1.977485	0.591837	0.605514	1.638484	0.705539	0.745085
3500	0.358000	2.206867	0.603499	0.614138	1.725948	0.717201	0.757041
3600	0.276400	2.268767	0.594752	0.631561	1.781341	0.731778	0.657902
3700	0.259100	2.536266	0.615160	0.584543	2.244898	0.793003	0.715823
3800	0.287700	2.357548	0.591837	0.516781	1.857143	0.743440	0.899610
3900	0.135400	2.300931	0.606414	0.611954	1.685131	0.705539	0.742290
4000	0.232200	2.530481	0.600583	0.621855	2.026239	0.766764	0.681805
4100	0.094700	2.492249	0.600583	0.640741	1.728863	0.714286	0.641773
4200	0.054000	2.811858	0.600583	0.648604	1.880466	0.731778	0.649045

Evaluate:
 [43/43 00:25]
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
labels: [0 6 1 1 4 2 4 3 1 1 1 3 5 6 3 3 5 3 4 0 4 0 0 5 0 0 0 6 6 0 4 1 2 6 0 4 1
 3 5 0 6 4 4 0 0 0 0 6 5 2 2 4 7 3 2 2 1 4 1 6 2 2 5 2 4 6 5 0 5 2 3 0 0 5
 0 5 5 2 2 1 0 4 6 3 3 4 2 0 6 1 4 5 2 2 6 2 4 2 1 6 0 2 2 4 0 4 4 2 0 4 5
 5 5 4 2 6 2 3 2 4 5 1 5 2 5 2 2 5 3 4 4 2 1 1 0 3 6 3 3 2 2 1 4 4 0 6 4 3
 0 2 2 3 6 5 3 2 5 2 0 0 4 6 1 0 6 4 0 1 5 2 5 3 0 4 6 4 3 0 1 2 5 0 2 3 1
 3 2 1 1 2 4 0 2 1 4 0 5 3 3 3 2 4 2 1 5 2 0 2 2 0 6 5 6 4 2 5 1 5 4 2 5 3
 0 2 0 4 6 6 3 4 5 1 3 5 5 1 3 3 4 3 4 1 1 1 4 3 5 5 5 2 2 6 6 5 2 0 4 6 2
 3 1 5 2 6 0 2 3 3 3 4 1 1 5 4 2 3 2 4 1 3 3 1 4 6 2 3 3 4 1 2 2 4 2 1 1 4
 1 1 0 6 0 3 3 4 3 3 2 2 6 2 6 4 6 3 6 0 5 4 3 5 3 0 1 5 1 5 5 4 1 0 5 5 3
 7 0 2 5 4 2 3 0 3 6 2]
preds: [1 6 1 1 4 2 4 3 1 1 1 3 5 6 3 3 5 3 4 0 1 0 0 2 0 0 0 6 6 0 4 1 2 6 0 4 1
 3 5 0 6 4 4 2 0 0 0 6 5 2 2 4 7 3 2 2 1 4 1 6 2 2 5 2 4 6 5 0 5 2 3 0 0 5
 0 5 5 1 2 1 0 4 4 3 3 4 2 0 6 1 4 5 2 2 6 2 4 2 1 6 0 2 2 4 0 4 4 2 0 4 5
 5 5 4 1 6 2 3 2 4 5 1 5 2 5 2 2 5 3 4 4 2 1 1 0 3 6 2 3 2 2 1 4 4 0 6 5 3
 0 2 2 3 6 5 3 2 5 2 0 1 4 6 1 1 6 4 0 1 5 2 5 3 0 4 6 4 3 2 1 2 5 1 2 2 1
 3 2 1 1 2 4 0 2 1 4 0 5 3 3 3 2 4 2 1 5 2 1 2 2 0 6 5 6 5 2 5 1 5 4 2 5 3
 0 2 0 4 6 6 3 4 5 2 3 5 5 1 3 3 4 3 4 0 1 2 4 3 5 5 5 2 2 6 6 5 2 0 4 6 2
 3 1 5 2 6 0 2 3 3 3 4 1 1 5 4 2 3 2 2 1 3 3 1 1 6 2 3 3 4 1 2 2 4 2 1 2 4
 1 1 0 6 4 3 3 4 3 3 2 2 6 2 6 4 6 3 6 0 5 4 3 5 3 0 1 5 1 5 5 4 2 0 5 4 3
 7 0 2 5 4 2 3 0 3 6 2]
              precision    recall  f1-score   support

       teens       0.98      0.83      0.90        48
    twenties       0.81      0.88      0.84        43
    thirties       0.86      0.97      0.91        65
    fourties       1.00      0.96      0.98        51
     fifties       0.94      0.91      0.92        53
     sixties       0.96      0.96      0.96        47
   seventies       1.00      0.97      0.99        35
    eighties       1.00      1.00      1.00         2

    accuracy                           0.93       344
   macro avg       0.94      0.94      0.94       344
weighted avg       0.93      0.93      0.93       344

[[40  5  2  0  1  0  0  0]
 [ 1 38  4  0  0  0  0  0]
 [ 0  2 63  0  0  0  0  0]
 [ 0  0  2 49  0  0  0  0]
 [ 0  2  1  0 48  2  0  0]
 [ 0  0  1  0  1 45  0  0]
 [ 0  0  0  0  1  0 34  0]
 [ 0  0  0  0  0  0  0  2]]

 {'eval_loss': 0.5100130438804626,
 'eval_model_preparation_time': 0.0075,
 'eval_accuracy': 0.9273255813953488,
 'eval_f1_score': 0.9377994131455086,
 'eval_MSE': 0.22093023255813954,
 'eval_MAE': 0.11046511627906977,
 'eval_MAE^M': 0.09850322569363941,
 'eval_runtime': 28.8235,
 'eval_samples_per_second': 11.935,
 'eval_steps_per_second': 1.492}

View project at https://wandb.ai/marian-lippold-hochschule-rheinmain/huggingface
View run at https://wandb.ai/marian-lippold-hochschule-rheinmain/huggingface/runs/a4ocvh0c

{'eval_loss': 0.5100130438804626,
 'eval_model_preparation_time': 0.0075,
 'eval_accuracy': 0.9273255813953488,
 'eval_f1_score': 0.9377994131455086,
 'eval_MSE': 0.22093023255813954,
 'eval_MAE': 0.11046511627906977,
 'eval_MAE^M': 0.09850322569363941,
 'eval_runtime': 28.8235,
 'eval_samples_per_second': 11.935,
 'eval_steps_per_second': 1.492}